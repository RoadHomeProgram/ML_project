---
title: "02a_loop_over_outcomes"
author: "Ryan Schubert"
date: "8/2/2021"
output: html_document
---


```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(data.table)
library(ggplot2)
library(corrplot)
library(visdat)
library(viridis)
library(glmnet)
library(ranger)
library(e1071)
library(MASS)
library(MLmetrics)
library(gbm)
library(caret)
library(MXM)
library(ROCR)
"%&%" = function(a,b) paste0(a,b)
set.seed(1234)

```

## read in data

```{r}
dir<-"C:\\Users\\rshoo\\OneDrive\\Desktop\\rush\\ML project\\replicate all response models\\"
data<-fread(dir %&%  "outcome_data_complete_cases.csv")
outcomes<-colnames(data)[grepl("Outcome",colnames(data))]
features<-colnames(data)[!grepl("Outcome",colnames(data)) & !(colnames(data) %in% c("MRN","delta_PCL","pct_PCL","PCL_SCORE_noE","PCL_DAY14_noE","delta_PCL_noE","COHORT_TYPE","pct_meaningful_reduction","pct_item_reduction","pct_matched_reduction","Outcome10ptnoE","Outcome10pct","Outcome50pct"))]
methods<-c("Ridge","elastic","gbm","SVMLinear","MMPClogistic","RF","naivelogistic","degenerate")
```

```{r}
generate_dataset<-function(data,featureVec,outcomeStr){
  keep<-c(featureVec,outcomeStr)
  outData<- data %>% dplyr::select(one_of(keep))
  return(outData)
}

estimateModelPerformance<-function(data,outcomeStr,k=5){
  fold_ids<-sample(1:k,nrow(data),replace = T)
  # table(fold_ids,tenPointData$Outcome10pt)#reasonably balanced folds with each class in each
  
  
  #initialize metrics matrices
  methods<-c("Ridge","elastic","gbm","SVMLinear","MMPClogistic","RF","naivelogistic","degenerate")
  accuracy_rate<-matrix(NA,nrow=k,ncol=length(methods))
  AUC_cv<-matrix(NA,nrow=k,ncol=length(methods))
  prediction_list<-vector(mode="list",length=k)
  colnames(accuracy_rate)<-methods
  colnames(AUC_cv)<-methods
  true_classes<-vector(mode="list",length(k))
  
  #tune grids
  ridge_tunegrid<-expand.grid(alpha = 0,
                              lambda = seq(0.001,0.1,by = 0.001))
  
  elastic_tunegrid<-expand.grid(alpha = seq(0,1,by=0.2),
                                lambda = seq(0.001,0.1,by = 0.001))
  
  gbm_tunegrid<-expand.grid(interaction.depth = c(1,2),
                        n.trees = c(500), 
                        shrinkage = c(0.001,0.01,0.1),
                        n.minobsinnode = c(1,3,5))
  
  svmL_tunegrid<-expand.grid(C=c(1,2,5,10))
  
  rf_grid<-expand.grid(mtry = 2,
                         splitrule = c("gini","extratrees"),
                         min.node.size = c(1, 3, 5))
  for (fold in 1:k){
    print(fold)
    holdout<-data[fold_ids == fold,] 
    holdout<-holdout %>% mutate(out=as.factor(if_else(.[[ncol(holdout)]]==0,"nonresponder","responder"))) %>% dplyr::select(-one_of(outcomeStr))
    holdin<-data[fold_ids!=fold,]
  
    MMPC_holdin_pred<-holdin %>% dplyr::select(-one_of(outcomeStr)) %>% as.matrix()
    MMPC_holdin_response<-holdin %>% dplyr::select(one_of(outcomeStr)) %>% unlist %>% unname()
    true_classes[[fold]]<-holdout %>% dplyr::select(out)
    #mutate(sum = .[[1]] + .[[2]])
    holdin<-holdin %>% mutate(out=as.factor(if_else(.[[ncol(holdin)]]==0,"nonresponder","responder"))) %>% dplyr::select(-one_of(outcomeStr))
    prediction_matrix<-as.data.frame(matrix(NA,ncol=length(methods),nrow=nrow(holdout)))
    colnames(prediction_matrix)<-methods
    formula<-as.formula("out ~ .")
    ridge_ctrl <- trainControl(method="cv", 
                               number=5, 
                               returnResamp="all",
                               classProbs=TRUE,
                               summaryFunction=twoClassSummary)
  
    ridge_model <- train(formula,
                         data=holdin,
                         method = "glmnet", 
                         trControl = ridge_ctrl,
                         verbose=F,
                         metric='ROC',
                         family="binomial",
                         tuneGrid = ridge_tunegrid)
    prediction_matrix[,1]<-predict(ridge_model,holdout,type="prob")[,2]
    accuracy_rate[fold,1]<-sum(diag(table(predict(ridge_model,holdout,type="raw"),holdout$out)))/nrow(holdout)
    predObj<-prediction(predict(ridge_model,holdout,type="prob")[,2],as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,1]<-perf@y.values[[1]]
  cat("ridge",fold,"\n")
    #ridge surprisingly predicted several as nonresponders unlike rf
    #lets tune on a larger set of alphas
    elastic_ctrl <- trainControl(method="cv", 
                               number=5, 
                               returnResamp="all",
                               classProbs=TRUE,
                               summaryFunction=twoClassSummary)
  
    elastic_model <- train(formula,
                         data=holdin,
                         method = "glmnet", 
                         trControl = elastic_ctrl,
                         verbose=F,
                         metric='ROC',
                         family="binomial",
                         tuneGrid = elastic_tunegrid)
    prediction_matrix[,2]<-predict(elastic_model,holdout,type="prob")[,2]
    accuracy_rate[fold,2]<-sum(diag(table(predict(elastic_model,holdout,type="raw"),holdout$out)))/nrow(holdout)
    predObj<-prediction(predict(elastic_model,holdout,type="prob")[,2],as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,2]<-perf@y.values[[1]]
    cat("elastic",fold,"\n")
    
    #elastic net seems slightly more accurate since it predicts fewer people as being nonresponders so not great
    #next lets try a gbm
    gbm_ctrl <- trainControl(method="cv", 
                               number=5, 
                               returnResamp="all",
                               classProbs=TRUE,
                               summaryFunction=twoClassSummary)
  
    gbm_model <- train(formula,
                      data=holdin,
                      method = "gbm", 
                      trControl = gbm_ctrl,
                      verbose=F,
                      metric='ROC',
                      distribution="bernoulli",
                      tuneGrid = gbm_tunegrid)
    prediction_matrix[,3]<-predict(gbm_model,holdout,type="prob")[,2]
    accuracy_rate[fold,3]<-sum(diag(table(predict(gbm_model,holdout,type="raw"),holdout$out)))/nrow(holdout)
    predObj<-prediction(predict(gbm_model,holdout,type="prob")[,2],as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,3]<-perf@y.values[[1]]
    cat("gbm",fold,"\n")
    #Next fit a SVM with a linear kernel
    svmL_ctrl <- trainControl(method="cv", 
                               number=5, 
                               returnResamp="all",
                               classProbs=TRUE,
                               summaryFunction=twoClassSummary)
  
    svmL_model <- train(formula,
                      data=holdin,
                      method = "svmLinear", 
                      trControl = svmL_ctrl,
                      verbose=F,
                      metric='ROC',
                      distribution="bernoulli",
                      tuneGrid = svmL_tunegrid)
    prediction_matrix[,4]<-predict(svmL_model,holdout,type="prob")[,2]
    accuracy_rate[fold,4]<-sum(diag(table(predict(svmL_model,holdout,type="raw"),holdout$out)))/nrow(holdout)
    predObj<-prediction(predict(svmL_model,holdout,type="prob")[,2],as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,4]<-perf@y.values[[1]]
  cat("svm",fold,"\n")
    mmpcObj <-MMPC( target  = MMPC_holdin_response,            
                  dataset = MMPC_holdin_pred,            
                  max_k = 3,          
                  threshold = 0.2,                                      
                  test = 'testIndFisher',   
                  ini = NULL,                                           
                  hash =  TRUE, 
                  hashObject = NULL,
                  ncores = 1,         
                  backward = TRUE)
   
    
    form<-"out ~ " %&% paste(colnames(holdin)[mmpcObj@selectedVars],collapse =" + " )
    MMPCLogistic<-glm(form, data = holdin, family="binomial")
    prediction_matrix[,5]<-predict(MMPCLogistic,holdout,type="response")
    accuracy_rate[fold,5]<-sum(diag(table(round(predict(MMPCLogistic,holdout,type="response")),holdout$out)))/nrow(holdout)
    predObj<-prediction(predict(MMPCLogistic,holdout,type="response"),as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,5]<-perf@y.values[[1]]
    cat("mmpc",fold,"\n")
    
    
    #test RF
    rf_ctrl <- trainControl(method="cv", number=5, returnResamp = "all",classProbs=TRUE)
    # str(holdin)
    rf_model <- train(formula,
                  data = holdin,
                  method = "ranger",
                  verbose=F,
                  trControl = rf_ctrl,
                  metric="ROC",
                  tuneGrid = rf_grid)
    prediction_matrix[,6]<-predict(rf_model,holdout,type="prob")[,2]
      accuracy_rate[fold,6]<-sum(diag(table(predict(rf_model,holdout,type="raw"),holdout$out)))/nrow(holdout)
      predObj<-prediction(predict(rf_model,holdout,type="prob")[,2],as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,6]<-perf@y.values[[1]]
      cat("rf",fold,"\n")
      #naive logistic model
      naiveLogistic<-glm(form, data = holdin, family="binomial")
      prediction_matrix[,7]<-predict(naiveLogistic,holdout,type="response")
      accuracy_rate[fold,7]<-sum(diag(table(round(predict(naiveLogistic,holdout,type="response")),holdout$out)))/nrow(holdout)
      predObj<-prediction(predict(naiveLogistic,holdout,type="response"),as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,7]<-perf@y.values[[1]]
      cat("naive",fold,"\n")
    #lastly what is the prediction accuracy when we just predict everything as belonging to the responder class
    prediction_matrix[,8]<-rep(1,nrow(prediction_matrix))
    accuracy_rate[fold,8]<-1-sum(holdout$out=="nonresponder")/nrow(holdout)
    predObj<-prediction(rep(1,length(holdout$out)),as.numeric(holdout$out)-1)
    perf<-performance(predObj,"auc")
    AUC_cv[fold,8]<-perf@y.values[[1]]
    cat("degen",fold,"\n")
    prediction_list[[fold]]<-cbind.data.frame(prediction_matrix,holdout)
  }
  pred_df<-bind_rows(prediction_list,.id="id")
  class_df<-bind_rows(true_classes,.id="id")
  return(list(acc=accuracy_rate,AUCROC=AUC_cv,predictions=pred_df,classes=class_df))
}


```

```{r}
# outcomes<-outcomes[5:8]
for (i in outcomes){
  input<-generate_dataset(data,featureVec = features,i)
  output<-estimateModelPerformance(input,i,5)
  fwrite(output$acc, dir %&% i %&% "_accuracy.csv")
  fwrite(output$AUCROC, dir %&% i %&% "_AUC_ROC.csv")
  fwrite(output$predictions,dir %&% i %&% "_predictions.csv")
  fwrite(output$classes,dir %&% i %&% "_classes.csv")
}
# outcomeStr<-outcomes[1]
```
